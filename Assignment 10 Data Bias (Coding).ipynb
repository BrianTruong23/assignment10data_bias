{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c07e10",
   "metadata": {},
   "source": [
    "## Section: \n",
    "\n",
    "    1. Set Up Toxic Threshold\n",
    "    2. Set up hypothesis\n",
    "    3. Set Up Example for the toxic tests. \n",
    "    4. Get toxicity score and determine if toxic based on threshold and get the actual score in a dataframe\n",
    "    5. Evaluate the fairness of the model\n",
    "    6. Finding and Results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a15806",
   "metadata": {},
   "source": [
    "## 1) Determine the Toxic Threshold\n",
    "\n",
    "For this section, I will take 10 sentences for both non-toxic and toxic comments and determine the threshold for the toxicity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc1dfe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \" Ref SS Ponzi Scheme   Hi Padillah  It is not my opinion that I am trying to impose here although it may appear to be so I am just highlighting the fact that it remains controversial whether it is or isnt a Ponzi Scheme even if a legal one so you cannot state as a fact that it is not a Ponzi Scheme I saw the reference and the perpetrator itself cannot be treated as a reliable source In fact claiming it is not a Ponzi Scheme seems to be an opinion in itself My point is that a claim should not be made either way and the edit in question just accomplishes that   Thank you  Virat\"\n",
    "sentence2 = \"Not sure whether this is notable enough to be mentioned in the article but youre right – versions later than 6 2001 can open files created by all previous versions but save files only in its own format with a suffix of msX where X is the version number 7 8 9 10 11 12 This is intentional of course Besides all versions but 7 save files in a compressed format ☭共产主义万岁★\"\n",
    "sentence3 = \"It says it right there that it IS a type The Type of institution is needed in this case because there are three levels of SUNY schools  University Centers and Doctoral Granting Institutions  State Colleges  Community Colleges  It is needed in this case to clarify that UB is a SUNY Center It says it even in Binghamton University University at Albany State University of New York and Stony Brook University Stop trying to say its not because I am totally right in this case\"\n",
    "sentence4 = \" Thank you   James thank you for reverting that horrible vandalism from my user page   \"\n",
    "sentence5 = \"  Reason for banning throwing   This article needs a section on why throwing is banned At the moment to a noncricket fan it seems kind of arbitrary\"\n",
    "sentence6 = \" Argh   Some random idiot deleted the whole Japan article \"\n",
    "sentence7 = \" Bold textYOU SUCK     U SUCK HANNAH MONTANA\"\n",
    "sentence8 = \"where I feel like a man instead of an idiot\"\n",
    "sentence9 = \"Karl Tearle is a mop haired twat\"\n",
    "sentence10 = \" willeys    if u are a male with no willey then u are likley to be gay lol\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2fe0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = [sentence6,sentence7,sentence8,sentence9,sentence10]\n",
    "non_toxic_comments = [sentence1,sentence2,sentence3,sentence4,sentence5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4841710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is the average of toxicity score for non-toxic comments 0.1107129858\n",
      " This is the average of toxicity score for toxic comments 0.7550427519999999\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'secret-key'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "\n",
    "def get_average(list_comments):\n",
    "    \n",
    "    sum_score = 0.0\n",
    "\n",
    "    for comment in list_comments:\n",
    "\n",
    "\n",
    "        analyze_request = {\n",
    "          'comment': { 'text': comment },\n",
    "          'requestedAttributes': {'TOXICITY': {}}\n",
    "        }\n",
    "\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "\n",
    "        toxicity_score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "\n",
    "        sum_score += float(toxicity_score)\n",
    "\n",
    "    average_non_toxic = (sum_score / len(list_comments))\n",
    "        \n",
    "    return average_non_toxic\n",
    "\n",
    "  \n",
    "print(\" This is the average of toxicity score for non-toxic comments\", get_average(non_toxic_comments))\n",
    "print(\" This is the average of toxicity score for toxic comments\", get_average(toxic_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210531ac",
   "metadata": {},
   "source": [
    "### Findings: \n",
    "\n",
    "As the average of toxicity score for non-toxic comments is around 0.11 and the average of toxicity score for toxic comments is around 0.76, I would choose the threshold of toxicity around 0.4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7134798",
   "metadata": {},
   "source": [
    "## 2) Set up hypothesis\n",
    "\n",
    "For this section, I will set up the hypothesis. \n",
    "\n",
    "###  My hypothesis is that Perspective will be more likely to mark the comment with all-caps words as toxic when compared to non-cap words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e2741",
   "metadata": {},
   "source": [
    "## 3) Set Up Example for the toxic tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b79723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 examples of cap toxic and 3 cap non toxic \n",
    "# 3 example of non cap toxic and 3 non cap non toxic \n",
    "\n",
    "# not toxic\n",
    "sentence1 = \"YOU ARE AN AMAZING PERSON AND I FEEL LUCKY TO KNOW YOU. YOUR POSITIVITY AND ENCOURAGEMENT HAVE MADE A DIFFERENCE IN MY LIFE AND I AM GRATEFUL FOR YOU.\"\n",
    "sentence2 = \"WHAT THE HELL    JUSTIN\"\n",
    "sentence3 = \"WPSOAPBOX WPFORUM ETC PLEASE ENGAGE IN YOUR CONSPIRATORIAL FANTASIES ELSEWHERE.\"\n",
    "\n",
    "sentence4 = \"FIRESTAR IS A POWER HUNGRY ARSE\"\n",
    "sentence5 = \"MONKEY B UTT SCRFATCHER MONKEY BUTT SCRATCH MONKEY BUTT SCRATCHER\"\n",
    "sentence6 = \"ANOYMOUS ARE ARE A BUNCH OF CUNTS WHICH ARE SCARED TO SHOW THEM SELVES TO THE REAL WORLD\"\n",
    "\n",
    "sentence7 = \"Thanks for the comment about Wikidefenderness I like that one I usually wikiling Wikidefender I agree that at first he was somewhat innocent but now have my doubts as he is being really agressive about the whole matter\"\n",
    "sentence8 = \"   That Stephen Barrett is not Board Certified is not a viewpoint It is a fact a well documented one at that I dont see how WPPROMINENCE applies    \"\n",
    "sentence9 = \"This is a REDIRECT discussion page Please do not leave article related discussion here  Please go to the articles discussion page\"\n",
    "\n",
    "sentence10 = \" willeys    if u are a male with no willey then u are likley to be gay lol\"\n",
    "sentence11 = \"kevin bravo is a faggot\"\n",
    "sentence12 = \"Shut up please this consensus is over\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bd0a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [sentence1,sentence2,sentence3,sentence4,sentence5,sentence6,sentence7,sentence8,sentence9,sentence10, sentence11,sentence12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad3d26",
   "metadata": {},
   "source": [
    "## 4) Get toxicity score and determine if toxic or not based on threshold and combine the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b08dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_comment_list = []\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "actual_toxic_list = [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "\n",
    "actual_cap_list =   [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "def assign_toxicity_score_for_comment(comment):\n",
    "    \n",
    "    analyze_request = {\n",
    "      'comment': { 'text': comment},\n",
    "      'requestedAttributes': {'TOXICITY': {}}\n",
    "    }\n",
    "\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "\n",
    "    toxicity_score = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
    "    \n",
    "    return toxicity_score\n",
    "\n",
    "def toxic_or_not(toxicity_score):\n",
    "    if toxicity_score >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "for i in range(len(comment_list)):\n",
    "    \n",
    "    comment_dic = {}\n",
    "    \n",
    "    comment = comment_list[i]\n",
    "    \n",
    "    toxicity_score = assign_toxicity_score_for_comment(comment)\n",
    "    \n",
    "    toxic = toxic_or_not(toxicity_score)\n",
    "    \n",
    "    actual_toxic = actual_toxic_list[i]\n",
    "    all_cap = actual_cap_list[i]\n",
    "    \n",
    "    comment_dic[\"comment\"] = comment\n",
    "    comment_dic[\"toxic\"] = toxic\n",
    "    comment_dic[\"actual_toxic\"] = actual_toxic\n",
    "    comment_dic[\"actual_cap\"] = all_cap\n",
    "    \n",
    "    list_of_comment_list.append(comment_dic)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11c04b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>actual_toxic</th>\n",
       "      <th>actual_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOU ARE AN AMAZING PERSON AND I FEEL LUCKY TO ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHAT THE HELL    JUSTIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPSOAPBOX WPFORUM ETC PLEASE ENGAGE IN YOUR CO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIRESTAR IS A POWER HUNGRY ARSE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MONKEY B UTT SCRFATCHER MONKEY BUTT SCRATCH MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANOYMOUS ARE ARE A BUNCH OF CUNTS WHICH ARE SC...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thanks for the comment about Wikidefenderness ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>That Stephen Barrett is not Board Certified...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This is a REDIRECT discussion page Please do n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>willeys    if u are a male with no willey the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kevin bravo is a faggot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shut up please this consensus is over</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  toxic  actual_toxic  \\\n",
       "0   YOU ARE AN AMAZING PERSON AND I FEEL LUCKY TO ...      0             0   \n",
       "1                             WHAT THE HELL    JUSTIN      1             0   \n",
       "2   WPSOAPBOX WPFORUM ETC PLEASE ENGAGE IN YOUR CO...      0             0   \n",
       "3                     FIRESTAR IS A POWER HUNGRY ARSE      1             1   \n",
       "4   MONKEY B UTT SCRFATCHER MONKEY BUTT SCRATCH MO...      1             1   \n",
       "5   ANOYMOUS ARE ARE A BUNCH OF CUNTS WHICH ARE SC...      1             1   \n",
       "6   Thanks for the comment about Wikidefenderness ...      0             0   \n",
       "7      That Stephen Barrett is not Board Certified...      0             0   \n",
       "8   This is a REDIRECT discussion page Please do n...      0             0   \n",
       "9    willeys    if u are a male with no willey the...      1             1   \n",
       "10                            kevin bravo is a faggot      1             1   \n",
       "11              Shut up please this consensus is over      1             1   \n",
       "\n",
       "    actual_cap  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  \n",
       "6            0  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  \n",
       "10           0  \n",
       "11           0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(list_of_comment_list, columns=['comment', 'toxic', \"actual_toxic\",\"actual_cap\"])\n",
    "  \n",
    "# print dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c4cd6",
   "metadata": {},
   "source": [
    "## 5) Evaluate the fairness of the classifier model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a09dc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = df[\"actual_toxic\"].values.tolist()\n",
    "y_predicted = df[\"toxic\"].values.tolist()\n",
    "\n",
    "cap_column = df[\"actual_cap\"]\n",
    "\n",
    "cap_indices = []\n",
    "\n",
    "no_cap_indices = []\n",
    "\n",
    "for i in range(len(cap_column)):\n",
    "    if cap_column[i] == 1:\n",
    "        cap_indices.append(i)\n",
    "    else:\n",
    "        no_cap_indices.append(i)\n",
    "\n",
    "y_actual_cap = [y_actual[i] for i in cap_indices]\n",
    "y_predicted_cap = [y_predicted[i] for i in cap_indices] \n",
    "\n",
    "y_actual_non_cap = [y_actual[i] for i in no_cap_indices]\n",
    "y_predicted_non_cap = [y_predicted[i] for i in no_cap_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4bfbd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (toxic) accuracy for all_cap = 1.0\n",
      "Class 0 (non_toxic) accuracy for all_cap = 0.6666666666666666\n",
      "Class 1 (toxic) accuracy for non_cap = 1.0\n",
      "Class 0 (non_toxic) accuracy for non_cap = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def class_wise_acc(y_actual, y_predicted):\n",
    "    total_p = 0\n",
    "    total_n = 0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    for i in range(len(y_predicted)):\n",
    "        if y_actual[i]==1:\n",
    "            total_p = total_p+1\n",
    "            if y_actual[i]==y_predicted[i]:\n",
    "               TP=TP+1\n",
    "        if y_actual[i]==0:\n",
    "            total_n=total_n+1\n",
    "            if y_actual[i]==y_predicted[i]:\n",
    "               TN=TN+1\n",
    "    return(TP/total_p, TN/total_n)\n",
    "\n",
    "class_1_acc_all_cap, class_0_acc_all_cap = class_wise_acc(y_actual_cap, y_predicted_cap)\n",
    "class_1_acc_non_cap, class_0_acc_non_cap = class_wise_acc(y_actual_non_cap, y_predicted_non_cap)\n",
    "\n",
    "print (f\"Class 1 (toxic) accuracy for all_cap = {class_1_acc_all_cap}\")\n",
    "print (f\"Class 0 (non_toxic) accuracy for all_cap = {class_0_acc_all_cap}\")\n",
    "print (f\"Class 1 (toxic) accuracy for non_cap = {class_1_acc_non_cap}\")\n",
    "print (f\"Class 0 (non_toxic) accuracy for non_cap = {class_0_acc_non_cap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f8dfb",
   "metadata": {},
   "source": [
    "## 6) Findings and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a26b6",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "* Class 1 (toxic) accuracy for all_cap = 1.0\n",
    "* Class 0 (non_toxic) accuracy for all_cap = 0.6666666666666666\n",
    "* Class 1 (toxic) accuracy for non_cap = 1.0\n",
    "* Class 0 (non_toxic) accuracy for non_cap = 1.0\n",
    "\n",
    "### Findings \n",
    "\n",
    "From the results, we noticed there is 66 percent chance that the persepctive AI predicts correctly if an all-cap sentence is a non-toxic. This proves there is a chance that the model is bias towards the all-cap as it will likely mark it as toxic rather than non-toxic. For the accuracy of all-cap sentence, it has a 100 percent accuracy of labelling it as toxic comments. For non-cap sentence, it also has pretty high percent accuracy to determine if the sentence is toxic or not. \n",
    "\n",
    "Because the test sample is very small, the results may not be reliable. However, it gives a good glimpse towards the fairness of the model when it is more likely to mark all-cap sentence as toxic. More experimentation with bigger sample size needs to be conducted before we can conclude that the model is bias towards all-cap sentence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
